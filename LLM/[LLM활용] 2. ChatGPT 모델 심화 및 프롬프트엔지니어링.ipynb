{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9ea9f549",
      "metadata": {},
      "source": [
        "# OpenAI API 강의 2\n",
        "## 주제: ChatGPT 모델 심화 및 프롬프트 엔지니어링"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b59af7f6",
      "metadata": {},
      "source": [
        "\n",
        "## 학습 목표\n",
        "- ChatGPT 모델 구조 및 기능 이해\n",
        "- 프롬프트 엔지니어링 기법 실습\n",
        "- System / User / Assistant 역할의 차이 학습\n",
        "- 다양한 프롬프트 스타일 비교 (지시형, 예시형, Few-shot 등)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ff326a4",
      "metadata": {},
      "source": [
        "\n",
        "## 1. ChatGPT 모델 개요\n",
        "| 항목 | 설명 |\n",
        "|------|------|\n",
        "| 모델 이름 | `gpt-4.1`, `gpt-4o-mini`, `gpt-3.5-turbo` 등 |\n",
        "| 모델 특징 | 대화형 자연어 처리에 최적화 |\n",
        "| 주요 기능 | 대화 유지, 문맥 기억, 다양한 역할(System/User/Assistant) |\n",
        "| 활용 예시 | 챗봇, 고객지원, 문서 요약, 질의응답, 코드 보조 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "25382192",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adam(Adaptive Moment Estimation)은 딥러닝에서 널리 사용되는 최적화 알고리즘 중 하나입니다. 이 알고리즘은 경량화된 효율성과 뛰어난 성능 덕분에 많은 딥러닝 프레임워크에서 기본 최적화 방법으로 채택되고 있습니다.\n",
            "\n",
            "### Adam의 주요 특징\n",
            "\n",
            "1. **모멘텀을 사용하는 최적화**:\n",
            "   - Adam은 과거의 기울기를 고려하여 현재의 기울기 업데이트에 모멘텀을 추가하는 방식으로 동작합니다. 이를 통해 스무딩 효과를 얻고, 경량화된 학습 속도를 유지할 수 있습니다.\n",
            "\n",
            "2. **적응형 학습률**:\n",
            "   - Adam은 각 파라미터에 대해 별도의 학습률을 조정합니다. 각 파라미터의 기울기 1차 순간(moment)과 2차 순간(variance)을 추정하여, 더 자주 업데이트되는 파라미터의 학습률은 줄이고, 적게 업데이트되는 파라미터의 학습률은 높입니다.\n",
            "\n",
            "3. **바라라 안정성**:\n",
            "   - 이 방법은 초깃값과 학습률에 대한 민감도가 낮아서, 비교적 좋은 성능을 보여줍니다.\n",
            "\n",
            "### Adam의 수식\n",
            "\n",
            "Adam은 다음과 같은 단계로 최적화됩니다:\n",
            "\n",
            "1. **1차 모멘트 추정**: 현재의 기울기로부터 첫 번째 모멘트를 추정합니다.\n",
            "   \\[\n",
            "   m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t\n",
            "   \\]\n",
            "   여기서 \\(g_t\\)는 현재의 기울기, \\(\\beta_1\\)는 모멘텀을 조정하는 하이퍼파라미터입니다.\n",
            "\n",
            "2. **2차 모멘트 추정**: 현재의 기울기의 제곱으로부터 두 번째 모멘트를 추정합니다.\n",
            "   \\[\n",
            "   v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2\n",
            "   \\]\n",
            "   \\(\\beta_2\\)는 2차 모멘트의 하이퍼파라미터입니다.\n",
            "\n",
            "3. **편향 보정**: 초기 단계에서는 \\(m_t\\)와 \\(v_t\\)가 0으로 시작되기 때문에 편향을 보정합니다.\n",
            "   \\[\n",
            "   \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}\n",
            "   \\]\n",
            "   \\[\n",
            "   \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n",
            "   \\]\n",
            "\n",
            "4. **파라미터 업데이트**: 최종적으로 파라미터를 업데이트합니다.\n",
            "   \\[\n",
            "   \\theta_{t+1} = \\theta_t - \\frac{\\alpha}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t\n",
            "   \\]\n",
            "   여기서 \\(\\alpha\\)는 학습률, \\(\\epsilon\\)은 0으로 나누는 것을 방지하는 작은 상수입니다.\n",
            "\n",
            "### Adam의 장점\n",
            "\n",
            "- 빠르고 효율적인 학습.\n",
            "- 다양한 문제에서 잘 작동(flagging).\n",
            "- 적응형 학습률 덕분에 각 파라미터에 대한 최적화 효과가 뛰어남.\n",
            "\n",
            "### Adam의 단점\n",
            "\n",
            "- 일반적으로 좋은 성능을 내지만 경우에 따라 큐딩이나 안정성이 떨어질 수 있습니다.\n",
            "- 하이퍼파라미터 조정이 필요할 수 있습니다.\n",
            "\n",
            "이렇게 Adam은 딥러닝에서 자주 사용되며, 성능과 효율성을 강조하는 현대적인 최적화 알고리즘으로 자리잡고 있습니다.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"너는 친절한 AI 강사야.\"},\n",
        "        {\"role\": \"user\", \"content\": \"딥러닝에서 나오는 adam에 대해 설명해줘.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "markdown_doc = response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3cc2c78d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Adam(Adaptive Moment Estimation)은 딥러닝에서 널리 사용되는 최적화 알고리즘 중 하나입니다. 이 알고리즘은 경량화된 효율성과 뛰어난 성능 덕분에 많은 딥러닝 프레임워크에서 기본 최적화 방법으로 채택되고 있습니다.\n",
              "\n",
              "### Adam의 주요 특징\n",
              "\n",
              "1. **모멘텀을 사용하는 최적화**:\n",
              "   - Adam은 과거의 기울기를 고려하여 현재의 기울기 업데이트에 모멘텀을 추가하는 방식으로 동작합니다. 이를 통해 스무딩 효과를 얻고, 경량화된 학습 속도를 유지할 수 있습니다.\n",
              "\n",
              "2. **적응형 학습률**:\n",
              "   - Adam은 각 파라미터에 대해 별도의 학습률을 조정합니다. 각 파라미터의 기울기 1차 순간(moment)과 2차 순간(variance)을 추정하여, 더 자주 업데이트되는 파라미터의 학습률은 줄이고, 적게 업데이트되는 파라미터의 학습률은 높입니다.\n",
              "\n",
              "3. **바라라 안정성**:\n",
              "   - 이 방법은 초깃값과 학습률에 대한 민감도가 낮아서, 비교적 좋은 성능을 보여줍니다.\n",
              "\n",
              "### Adam의 수식\n",
              "\n",
              "Adam은 다음과 같은 단계로 최적화됩니다:\n",
              "\n",
              "1. **1차 모멘트 추정**: 현재의 기울기로부터 첫 번째 모멘트를 추정합니다.\n",
              "   \\[\n",
              "   m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t\n",
              "   \\]\n",
              "   여기서 \\(g_t\\)는 현재의 기울기, \\(\\beta_1\\)는 모멘텀을 조정하는 하이퍼파라미터입니다.\n",
              "\n",
              "2. **2차 모멘트 추정**: 현재의 기울기의 제곱으로부터 두 번째 모멘트를 추정합니다.\n",
              "   \\[\n",
              "   v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2\n",
              "   \\]\n",
              "   \\(\\beta_2\\)는 2차 모멘트의 하이퍼파라미터입니다.\n",
              "\n",
              "3. **편향 보정**: 초기 단계에서는 \\(m_t\\)와 \\(v_t\\)가 0으로 시작되기 때문에 편향을 보정합니다.\n",
              "   \\[\n",
              "   \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}\n",
              "   \\]\n",
              "   \\[\n",
              "   \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n",
              "   \\]\n",
              "\n",
              "4. **파라미터 업데이트**: 최종적으로 파라미터를 업데이트합니다.\n",
              "   \\[\n",
              "   \\theta_{t+1} = \\theta_t - \\frac{\\alpha}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t\n",
              "   \\]\n",
              "   여기서 \\(\\alpha\\)는 학습률, \\(\\epsilon\\)은 0으로 나누는 것을 방지하는 작은 상수입니다.\n",
              "\n",
              "### Adam의 장점\n",
              "\n",
              "- 빠르고 효율적인 학습.\n",
              "- 다양한 문제에서 잘 작동(flagging).\n",
              "- 적응형 학습률 덕분에 각 파라미터에 대한 최적화 효과가 뛰어남.\n",
              "\n",
              "### Adam의 단점\n",
              "\n",
              "- 일반적으로 좋은 성능을 내지만 경우에 따라 큐딩이나 안정성이 떨어질 수 있습니다.\n",
              "- 하이퍼파라미터 조정이 필요할 수 있습니다.\n",
              "\n",
              "이렇게 Adam은 딥러닝에서 자주 사용되며, 성능과 효율성을 강조하는 현대적인 최적화 알고리즘으로 자리잡고 있습니다."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "208b3307",
      "metadata": {},
      "source": [
        "\n",
        "## 2. 역할(Role)의 이해\n",
        "| Role | 설명 | 예시 |\n",
        "|------|------|------|\n",
        "| system | 모델의 성격과 역할을 정의 | \"너는 데이터 분석 전문가야.\" |\n",
        "| user | 사용자의 질문이나 요청 | \"데이터 시각화 코드를 작성해줘.\" |\n",
        "| assistant | 모델이 생성한 응답 | \"다음은 matplotlib을 활용한 코드야...\" |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59cc14ac",
      "metadata": {},
      "source": [
        "\n",
        "## 3. 프롬프트 엔지니어링 기법\n",
        "| 기법 | 설명 | 예시 |\n",
        "|------|------|------|\n",
        "| 지시형 (Instruction) | 명확한 지시문 형태로 요청 | \"Python으로 파일 읽는 코드를 작성해줘.\" |\n",
        "| 예시형 (Example-based) | 예시를 통해 출력 패턴 유도 | \"입력: 사과 → 출력: Apple\" |\n",
        "| Few-shot | 여러 예시로 패턴 학습 유도 | \"입력: 고양이→Cat, 입력: 강아지→Dog\" |\n",
        "| Chain-of-Thought | 단계별 사고 유도 | \"단계별로 이유를 설명하면서 답변해줘.\" |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4629ecbe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adam (Adaptive Moment Estimation) is one of the widely used optimization algorithms in deep learning. This algorithm is adopted as the default optimization method in many deep learning frameworks due to its lightweight efficiency and outstanding performance.\n",
            "\n",
            "### Key Features of Adam\n",
            "\n",
            "1. **Momentum-Based Optimization**:\n",
            "   - Adam operates by incorporating momentum into the current gradient update based on past gradients. This results in a smoothing effect, allowing for a stable and efficient learning pace.\n",
            "\n",
            "2. **Adaptive Learning Rate**:\n",
            "   - Adam adjusts separate learning rates for each parameter. It estimates the first moment (mean) and the second moment (variance) of each parameter’s gradient to decrease the learning rate for parameters that are updated frequently, while increasing it for parameters that are updated less often.\n",
            "\n",
            "3. **Robustness to Initialization**:\n",
            "   - This method exhibits relatively good performance with low sensitivity to initial values and learning rates.\n",
            "\n",
            "### Adam's Formula\n",
            "\n",
            "Adam is optimized through the following steps:\n",
            "\n",
            "1. **First Moment Estimation**: It estimates the first moment from the current gradient.\n",
            "   \\[\n",
            "   m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t\n",
            "   \\]\n",
            "   Here, \\(g_t\\) is the current gradient, and \\(\\beta_1\\) is a hyperparameter that adjusts the momentum.\n",
            "\n",
            "2. **Second Moment Estimation**: It estimates the second moment from the square of the current gradient.\n",
            "   \\[\n",
            "   v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2\n",
            "   \\]\n",
            "   \\(\\beta_2\\) is the hyperparameter for the second moment.\n",
            "\n",
            "3. **Bias Correction**: Since \\(m_t\\) and \\(v_t\\) start at zero in the initial stages, bias correction is applied.\n",
            "   \\[\n",
            "   \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}\n",
            "   \\]\n",
            "   \\[\n",
            "   \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n",
            "   \\]\n",
            "\n",
            "4. **Parameter Update**: Finally, the parameters are updated.\n",
            "   \\[\n",
            "   \\theta_{t+1} = \\theta_t - \\frac{\\alpha}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t\n",
            "   \\]\n",
            "   Here, \\(\\alpha\\) is the learning rate, and \\(\\epsilon\\) is a small constant that prevents division by zero.\n",
            "\n",
            "### Advantages of Adam\n",
            "\n",
            "- Fast and efficient learning.\n",
            "- Works well across various problems.\n",
            "- The adaptive learning rate provides excellent optimization effects for each parameter.\n",
            "\n",
            "### Disadvantages of Adam\n",
            "\n",
            "- While it generally performs well, it may experience issues with convergence or stability in certain cases.\n",
            "- Hyperparameter tuning may be required.\n",
            "\n",
            "Thus, Adam has become a prominent optimization algorithm in deep learning, emphasizing performance and efficiency.\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"너는 번역가야.\"},\n",
        "        # {\"role\": \"user\", \"content\": \"입력: 안녕하세요 → 출력:\"}\n",
        "        {\"role\": \"user\", \"content\": f\"입력: {markdown_doc} → 출력:\"}\n",
        "    ]\n",
        ")\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "65243270",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Adam (Adaptive Moment Estimation) is one of the widely used optimization algorithms in deep learning. Proposed in 2014, Adam provides a lightweight learning rate and helps convergence more quickly and effectively than traditional methods like SGD (Stochastic Gradient Descent).\n",
              "\n",
              "The main features of Adam are as follows:\n",
              "\n",
              "1. **Adaptive Learning Rate**: Adam adjusts the learning rate individually for each parameter, allowing for more efficient parameter updates.\n",
              "\n",
              "2. **Momentum**: Adam incorporates the concept of momentum by considering previous gradients. This enables lightweight updates and reduces the problem of getting stuck in local minima.\n",
              "\n",
              "3. **Two Exponential Moving Averages**:\n",
              "   - **First Moment**: Represents the average of the gradients and acts as a type of momentum.\n",
              "   - **Second Moment**: Represents the average of the squared gradients, reflecting the magnitude of changes for each parameter.\n",
              "\n",
              "4. **Bias-Correction**: To address the issue of initial momentum estimates being close to zero, Adam employs a bias correction technique to adjust for imbalances in the early stages.\n",
              "\n",
              "The update formulas for Adam are as follows:\n",
              "\n",
              "1. \\( m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t \\)\n",
              "2. \\( v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2 \\)\n",
              "3. \\( \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t} \\)\n",
              "4. \\( \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t} \\)\n",
              "5. \\( \\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t \\)\n",
              "\n",
              "Where:\n",
              "- \\( g_t \\) is the gradient at the current step,\n",
              "- \\( m_t \\) is the first moment,\n",
              "- \\( v_t \\) is the second moment,\n",
              "- \\( \\beta_1 \\) and \\( \\beta_2 \\) are coefficients typically set to 0.9 and 0.999 for momentum,\n",
              "- \\( \\epsilon \\) is a small value for numerical stability.\n",
              "\n",
              "Thus, Adam is effective in solving various types of optimization problems and has become a very popular choice in multiple deep learning models."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "761d73e4",
      "metadata": {},
      "source": [
        "\n",
        "## 4. 다양한 프롬프트 스타일 비교\n",
        "### (1) 지시형 프롬프트\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "504841ce",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "다음은 인공지능의 장단점을 정리한 표입니다.\n",
            "\n",
            "| 장점                             | 단점                             |\n",
            "|----------------------------------|----------------------------------|\n",
            "| 1. **자동화**                   | 1. **고용 감소**                |\n",
            "| 2. **작업 효율성 향상**         | 2. **높은 초기 비용**           |\n",
            "| 3. **데이터 분석 및 예측**      | 3. **윤리적 문제**              |\n",
            "| 4. **24/7 작업 가능**           | 4. **의존성 증가**              |\n",
            "| 5. **정확성 및 일관성**         | 5. **보안 문제**                |\n",
            "| 6. **개인화된 서비스 제공**     | 6. **프라이버시 침해 가능성**   |\n",
            "| 7. **위험한 작업 대체**         | 7. **감정과 창의력 부족**       |\n",
            "\n",
            "위의 표는 인공지능의 주요 장점과 단점을 간략하게 정리한 것입니다. 각 항목은 더 깊이 있는 논의를 필요로 할 수 있습니다.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prompt = \"인공지능의 장단점을 표로 정리해줘.\"\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        ")\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "772e8275",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "다음은 인공지능의 장단점을 정리한 표입니다.\n",
              "\n",
              "| 장점                             | 단점                             |\n",
              "|----------------------------------|----------------------------------|\n",
              "| 1. **자동화**                   | 1. **고용 감소**                |\n",
              "| 2. **작업 효율성 향상**         | 2. **높은 초기 비용**           |\n",
              "| 3. **데이터 분석 및 예측**      | 3. **윤리적 문제**              |\n",
              "| 4. **24/7 작업 가능**           | 4. **의존성 증가**              |\n",
              "| 5. **정확성 및 일관성**         | 5. **보안 문제**                |\n",
              "| 6. **개인화된 서비스 제공**     | 6. **프라이버시 침해 가능성**   |\n",
              "| 7. **위험한 작업 대체**         | 7. **감정과 창의력 부족**       |\n",
              "\n",
              "위의 표는 인공지능의 주요 장점과 단점을 간략하게 정리한 것입니다. 각 항목은 더 깊이 있는 논의를 필요로 할 수 있습니다."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d4f720c",
      "metadata": {},
      "source": [
        "### (2) Few-shot 프롬프트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "33b578c0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "book\n"
          ]
        }
      ],
      "source": [
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"너는 한국어-영어 번역가야.\"},\n",
        "    {\"role\": \"user\", \"content\": \"입력: 학교 → 출력: school\"},\n",
        "    {\"role\": \"user\", \"content\": \"입력: 책 → 출력:\"}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=messages\n",
        ")\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "280035c9",
      "metadata": {},
      "source": [
        "\n",
        "## 5. 실습 과제\n",
        "1. 자신이 선택한 직업(예: 데이터 분석가, 마케터, 개발자)에 맞는 system role을 설정해보세요.\n",
        "2. 3가지 프롬프트 기법(지시형, 예시형, few-shot)을 각각 적용해 보세요.\n",
        "3. 어떤 방식이 가장 좋은 결과를 주었는지 토의해 봅시다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "713f4ac3",
      "metadata": {},
      "source": [
        "\n",
        "## 참고 자료\n",
        "- [OpenAI Chat Completions API Docs](https://platform.openai.com/docs/api-reference/chat)\n",
        "- [Prompt Engineering Guide](https://www.promptingguide.ai/)\n",
        "- [OpenAI Cookbook - Prompt Design](https://github.com/openai/openai-cookbook)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
